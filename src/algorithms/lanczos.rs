//! This module provides implementations of the symmetric Lanczos algorithm.
//!
//! It includes the standard one-pass algorithm, which generates and stores the basis
//! vectors, and a memory-efficient two-pass variant that regenerates the basis vectors
//! in a second pass to avoid storing them. The implementations are generic and
//! operate on any type that implements the `faer::matrix_free::LinOp` trait.

use crate::error::{LanczosError, LanczosErrorKind};
use faer::traits::math_utils::{add, mul, sub};
use faer::{
    Par,
    dyn_stack::{MemBuffer, MemStack},
    matrix_free::LinOp,
    prelude::*,
    traits::{ComplexField, RealField},
};

/// Represents the real, symmetric, tridiagonal matrix T_k generated by the Lanczos process.
///
/// The matrix is stored implicitly by its diagonal and off-diagonal elements.
#[derive(Debug, Clone)]
pub struct Tridiagonal<R: RealField> {
    /// The diagonal elements of the tridiagonal matrix (α_j).
    pub alphas: Vec<R>,
    /// The super/sub-diagonal elements of the tridiagonal matrix (β_j).
    /// `betas[j-1]` corresponds to β_j for j = 1, ..., steps_taken-1.
    /// The length is always `steps_taken - 1`.
    pub betas: Vec<R>,
    /// The actual number of steps performed before breakdown or completion.
    pub steps_taken: usize,
}

/// Contains the complete output of the standard one-pass Lanczos algorithm.
#[derive(Debug)]
pub struct LanczosOutput<T: ComplexField> {
    /// The matrix V_k whose columns are the orthonormal Lanczos basis vectors.
    pub v_k: Mat<T>,
    /// The tridiagonal matrix T_k, which is the projection of the operator onto the Krylov subspace.
    pub t_k: Tridiagonal<T::Real>,
}

/// Computes the tolerance for breakdown detection based on machine epsilon.
///
/// This provides better numerical robustness than hardcoded tolerances.
fn breakdown_tolerance<T: RealField>() -> T {
    // A small multiple of machine epsilon is a standard choice for breakdown detection.
    T::from_f64_impl(f64::EPSILON * 1000.0)
}

/// Performs a single step of the Lanczos recurrence relation.
///
/// This function implements the core three-term recurrence:
/// β_j v_{j+1} = A v_j - α_j v_j - β_{j-1} v_{j-1}
///
/// The result is written to the provided mutable matrix view `w`, which should be
/// pre-allocated by the caller. It returns the scalar coefficient α_j and an
/// `Option<β_j>`. A `None` value for β_j indicates that a breakdown has occurred
/// (β_j is numerically zero), and the iteration should terminate.
///
/// # Implementation Notes
///
/// The orthogonalization steps are implemented using `faer::zip!` to perform
/// fused multiply-subtract operations (`w <- w - c*v`) in-place. This avoids intermediate
/// memory allocations within the iterative loop, which is critical for performance
/// in high-performance computing contexts.
///
/// # Arguments
/// * `operator`: The linear operator A.
/// * `w`: Pre-allocated mutable matrix view for the output vector.
/// * `v_curr`: Current Lanczos vector v_j.
/// * `v_prev`: Previous Lanczos vector v_{j-1}.
/// * `beta_prev`: Previous beta coefficient β_{j-1}.
/// * `stack`: Memory stack for temporary allocations required by the operator.
///
/// # Returns
/// A tuple containing (α_j, Option<β_j>).
fn lanczos_recurrence_step<T: ComplexField, O: LinOp<T>>(
    operator: &O,
    mut w: MatMut<'_, T>,
    v_curr: MatRef<'_, T>,
    v_prev: MatRef<'_, T>,
    beta_prev: T::Real,
    stack: &mut MemStack,
) -> (T::Real, Option<T::Real>) {
    // Apply the operator: w = A * v_curr
    operator.apply(w.rb_mut(), v_curr, Par::Seq, stack);

    // Orthogonalize w against the previous Lanczos vector v_{j-1}.
    // This performs the operation w <- w - β_{j-1} * v_{j-1} in-place.
    let beta_prev_scaled = T::from_real_impl(&beta_prev);
    zip!(w.rb_mut(), v_prev).for_each(|unzip!(w_i, v_prev_i)| {
        *w_i = sub(w_i, &mul(&beta_prev_scaled, v_prev_i));
    });

    // Compute the diagonal element α_j = v_j^H * w.
    // At this point, w = A*v_j - β_{j-1}*v_{j-1}, which is the correct
    // intermediate vector for computing α_j.
    let alpha = T::real_part_impl(&(v_curr.adjoint() * w.rb())[(0, 0)]);

    // Orthogonalize w against the current Lanczos vector v_j.
    // This performs the operation w <- w - α_j * v_j in-place.
    let alpha_scaled = T::from_real_impl(&alpha);
    zip!(w.rb_mut(), v_curr).for_each(|unzip!(w_i, v_curr_i)| {
        *w_i = sub(w_i, &mul(&alpha_scaled, v_curr_i));
    });

    // Compute the off-diagonal element β_j = ||w||_2.
    // w is now the unnormalized next Lanczos vector, r_j.
    let beta = w.rb().norm_l2();

    // Check for breakdown. If β_j is close to zero, the Krylov subspace
    // is invariant, and the iteration must stop.
    let tolerance = breakdown_tolerance::<T::Real>();
    if beta <= tolerance {
        (alpha, None)
    } else {
        (alpha, Some(beta))
    }
}

struct LanczosStep<T: ComplexField> {
    /// The diagonal element α_j.
    alpha: T::Real,
    /// The off-diagonal element β_j.
    beta: T::Real,
}

/// Private struct that encapsulates the state of the Lanczos iteration.
///
/// This struct provides a clean, stateful representation of the Lanczos
/// recurrence, which can be consumed by different algorithm implementations.
/// It manages work vectors to avoid repeated heap allocations.
struct LanczosIteration<'a, T: ComplexField, O: LinOp<T>> {
    /// A reference to the linear operator.
    operator: &'a O,
    /// The previous Lanczos vector, v_{j-1}.
    v_prev: Mat<T>,
    /// The current Lanczos vector, v_j.
    v_curr: Mat<T>,
    /// Work vector for intermediate computations.
    work: Mat<T>,
    /// The previous beta coefficient, β_{j-1}.
    beta_prev: T::Real,
    /// The current iteration number.
    k: usize,
    /// The maximum number of iterations to perform.
    max_k: usize,
}

impl<'a, T: ComplexField, O: LinOp<T>> LanczosIteration<'a, T, O>
where
    T::Real: RealField,
{
    /// Creates a new `LanczosIteration` instance.
    ///
    /// # Returns
    /// A `Result` containing the new instance or a `LanczosError` if the input vector is zero.
    fn new(operator: &'a O, b: MatRef<'_, T>, max_k: usize) -> Result<Self, LanczosError> {
        let b_norm = b.norm_l2();
        let zero_threshold = breakdown_tolerance::<T::Real>();
        if b_norm <= zero_threshold {
            return Err(LanczosErrorKind::InputError(
                "Input vector `b` must not be a zero vector.".to_string(),
            )
            .into());
        }

        let mut v1 = Mat::zeros(b.nrows(), 1);
        v1.as_mut().copy_from(&b);
        let inv_norm = T::from_real_impl(&T::Real::recip_impl(&b_norm));
        v1 = &v1 * Scale(inv_norm);

        Ok(Self {
            operator,
            v_prev: Mat::zeros(b.nrows(), 1),
            v_curr: v1,
            work: Mat::zeros(b.nrows(), 1),
            beta_prev: T::Real::zero_impl(),
            k: 0,
            max_k,
        })
    }

    /// Performs the next step of the Lanczos iteration.
    fn next_step(&mut self, stack: &mut MemStack) -> Option<LanczosStep<T>> {
        if self.k >= self.max_k {
            return None;
        }

        // Use the reusable recurrence function with pre-allocated work vector.
        let (alpha, beta_option) = lanczos_recurrence_step(
            self.operator,
            self.work.as_mut(),
            self.v_curr.as_ref(),
            self.v_prev.as_ref(),
            T::Real::copy_impl(&self.beta_prev),
            stack,
        );

        self.k += 1;

        match beta_option {
            Some(beta) => {
                // Normalize: v_{j+1} = work / β_j (in-place)
                let inv_beta = T::from_real_impl(&T::Real::recip_impl(&beta));
                zip!(self.work.as_mut()).for_each(|unzip!(w_i)| {
                    *w_i = mul(w_i, &inv_beta);
                });

                // Update state for the next iteration using move semantics (no cloning).
                // Swap the vectors to avoid cloning: v_prev <- v_curr, v_curr <- work
                core::mem::swap(&mut self.v_prev, &mut self.v_curr);
                core::mem::swap(&mut self.v_curr, &mut self.work);
                self.beta_prev = T::Real::copy_impl(&beta);

                Some(LanczosStep { alpha, beta })
            }
            None => {
                // Breakdown occurred. Return the computed alpha but a zero beta.
                Some(LanczosStep {
                    alpha,
                    beta: T::Real::zero_impl(),
                })
            }
        }
    }
}

/// Performs the standard one-pass symmetric Lanczos algorithm.
///
/// This function executes `k` steps of the Lanczos process, storing the generated
/// basis vectors in the columns of the matrix `v_k`.
///
/// # Arguments
/// * `operator`: A linear operator that implements `faer::matrix_free::LinOp`.
/// * `b`: The starting vector. Must not be a zero vector.
/// * `k`: The number of iterations to perform.
///
/// # Returns
/// A `Result` containing the `LanczosOutput` on success, or a `LanczosError` on failure.
pub fn lanczos_standard<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    k: usize,
) -> Result<LanczosOutput<T>, LanczosError>
where
    T::Real: RealField,
{
    let b_norm = b.norm_l2();
    let zero_threshold = breakdown_tolerance::<T::Real>();
    if b_norm <= zero_threshold {
        return Err(LanczosErrorKind::InputError(
            "The initial vector `b` must not be a zero vector.".to_string(),
        )
        .into());
    }

    let mut v_k = Mat::<T>::zeros(operator.nrows(), k);
    let mut alphas = Vec::with_capacity(k);
    let mut betas = Vec::with_capacity(k - 1);

    let mut lanczos_iter = LanczosIteration::new(operator, b, k)?;
    v_k.col_mut(0)
        .copy_from(lanczos_iter.v_curr.as_ref().col(0));

    let mut steps_taken = 0;
    let mut mem = MemBuffer::new(operator.apply_scratch(1, Par::Seq));
    let mut stack = MemStack::new(&mut mem);

    for i in 0..k {
        if let Some(step) = lanczos_iter.next_step(&mut stack) {
            alphas.push(step.alpha);
            steps_taken += 1;

            // A zero beta indicates that breakdown has occurred.
            let tolerance = breakdown_tolerance::<T::Real>();
            if step.beta <= tolerance {
                break;
            }

            if i < k - 1 {
                betas.push(step.beta);
                // Copy the current vector from the iterator state after the step
                v_k.col_mut(i + 1)
                    .copy_from(lanczos_iter.v_curr.as_ref().col(0));
            }
        } else {
            break;
        }
    }

    Ok(LanczosOutput {
        v_k: v_k.as_ref().get(.., 0..steps_taken).to_owned(),
        t_k: Tridiagonal {
            alphas,
            betas,
            steps_taken,
        },
    })
}

/// Performs the first pass of the two-pass Lanczos algorithm.
///
/// This pass computes the coefficients of the tridiagonal matrix `T_k` without storing
/// the Lanczos basis vectors, resulting in an O(n) memory footprint.
///
/// # Arguments
/// * `operator`: A linear operator that implements `faer::matrix_free::LinOp`.
/// * `b`: The starting vector. Must not be a zero vector.
/// * `k`: The number of iterations to perform.
///
/// # Returns
/// A `Result` containing the `Tridiagonal` matrix data on success, or a `LanczosError`.
pub fn lanczos_pass_one<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    k: usize,
) -> Result<Tridiagonal<T::Real>, LanczosError>
where
    T::Real: RealField,
{
    let b_norm = b.norm_l2();
    let zero_threshold = breakdown_tolerance::<T::Real>();
    if b_norm <= zero_threshold {
        return Err(LanczosErrorKind::InputError(
            "The initial vector `b` must not be a zero vector.".to_string(),
        )
        .into());
    }

    let mut alphas = Vec::with_capacity(k);
    let mut betas = Vec::with_capacity(k - 1);

    let mut lanczos_iter = LanczosIteration::new(operator, b, k)?;

    let mut steps_taken = 0;
    let mut mem = MemBuffer::new(operator.apply_scratch(1, Par::Seq));
    let mut stack = MemStack::new(&mut mem);

    for i in 0..k {
        if let Some(step) = lanczos_iter.next_step(&mut stack) {
            alphas.push(step.alpha);
            steps_taken += 1;

            // A zero beta indicates that breakdown has occurred.
            let tolerance = breakdown_tolerance::<T::Real>();
            if step.beta <= tolerance {
                break;
            }

            if i < k - 1 {
                betas.push(step.beta);
            }
        } else {
            break;
        }
    }

    Ok(Tridiagonal {
        alphas,
        betas,
        steps_taken,
    })
}

/// Performs the second pass of the two-pass Lanczos algorithm.
///
/// This pass reconstructs the solution vector `x_k = V_k * y_k` by regenerating the
/// Lanczos basis vectors on-the-fly using the coefficients from the first pass.
///
/// # Arguments
/// * `operator`: A linear operator that implements `faer::matrix_free::LinOp`.
/// * `b`: The original starting vector.
/// * `t_k`: The tridiagonal matrix data generated by `lanczos_pass_one`.
/// * `y_k`: The coefficient vector, typically computed as `f(T_k) * e_1 * ||b||`.
///
/// # Returns
/// A `Result` containing the final approximate solution vector `x_k`.
pub fn lanczos_pass_two<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    t_k: &Tridiagonal<T::Real>,
    y_k: MatRef<'_, T>,
) -> Result<Mat<T>, LanczosError>
where
    T::Real: RealField,
{
    let b_norm = b.norm_l2();
    let zero_threshold = breakdown_tolerance::<T::Real>();
    if b_norm <= zero_threshold {
        return Err(LanczosErrorKind::InputError(
            "The initial vector `b` must not be a zero vector.".to_string(),
        )
        .into());
    }
    if t_k.steps_taken != y_k.nrows() {
        return Err(LanczosErrorKind::DimensionMismatch {
            operator_cols: t_k.steps_taken,
            vector_rows: y_k.nrows(),
        }
        .into());
    }
    if t_k.steps_taken == 0 {
        return Ok(Mat::zeros(b.nrows(), 1));
    }

    let b_norm = b.norm_l2();
    let mut v_prev = Mat::<T>::zeros(b.nrows(), 1);
    let mut v_curr = Mat::<T>::zeros(b.nrows(), 1);
    v_curr.as_mut().copy_from(&b);
    let inv_norm = T::from_real_impl(&T::Real::recip_impl(&b_norm));
    v_curr = &v_curr * Scale(inv_norm);

    // Initialize the solution with the first term: x_k = y_1 * v_1
    let mut x_k = &v_curr * Scale(T::copy_impl(&y_k[(0, 0)]));

    let mut mem = MemBuffer::new(operator.apply_scratch(1, Par::Seq));
    let mut stack = MemStack::new(&mut mem);

    for j in 0..t_k.steps_taken - 1 {
        let alpha_j = T::Real::copy_impl(&t_k.alphas[j]);
        let beta_j = T::Real::copy_impl(&t_k.betas[j]);
        let beta_prev = if j == 0 {
            T::Real::zero_impl()
        } else {
            T::Real::copy_impl(&t_k.betas[j - 1])
        };

        // Re-execute the recurrence step to get the unnormalized next vector in work.
        let mut work = Mat::<T>::zeros(b.nrows(), 1);
        let (computed_alpha, computed_beta_option) = lanczos_recurrence_step(
            operator,
            work.as_mut(),
            v_curr.as_ref(),
            v_prev.as_ref(),
            beta_prev,
            &mut stack,
        );

        // In debug builds, verify numerical stability by comparing the recomputed
        // coefficients against the stored ones from the first pass. A significant
        // deviation can indicate a loss of orthogonality.
        #[cfg(debug_assertions)]
        {
            let tolerance = breakdown_tolerance::<T::Real>() * T::Real::from_f64_impl(10.0);
            let alpha_diff = T::Real::abs_impl(
                &(T::Real::copy_impl(&computed_alpha) - T::Real::copy_impl(&alpha_j)),
            );
            if alpha_diff > tolerance {
                eprintln!(
                    "Warning: Alpha mismatch in second pass at step {j}: stored={:?}, computed={:?}",
                    alpha_j, computed_alpha
                );
            }
            if let Some(ref computed_beta) = computed_beta_option {
                let beta_diff = T::Real::abs_impl(
                    &(T::Real::copy_impl(computed_beta) - T::Real::copy_impl(&beta_j)),
                );
                if beta_diff > tolerance {
                    eprintln!(
                        "Warning: Beta mismatch in second pass at step {j}: stored={:?}, computed={:?}",
                        beta_j, computed_beta
                    );
                }
            }
        }

        // Ensure no unexpected breakdown occurs in the second pass.
        if computed_beta_option.is_none() {
            return Err(LanczosErrorKind::InputError(format!(
                "Unexpected breakdown in second pass at step {}",
                j
            ))
            .into());
        }

        // Normalize using the stored beta_j from the first pass for performance and reproducibility.
        let inv_beta = T::from_real_impl(&T::Real::recip_impl(&beta_j));
        zip!(work.as_mut()).for_each(|unzip!(w_i)| {
            *w_i = mul(w_i, &inv_beta);
        });

        // Accumulate into the solution vector using fused AXPY operation: x_k <- x_k + y_{j+1} * v_{j+1}
        let coeff = T::copy_impl(&y_k[(j + 1, 0)]);
        zip!(x_k.as_mut(), work.as_ref()).for_each(|unzip!(x_i, v_i)| {
            *x_i = add(x_i, &mul(&coeff, v_i));
        });

        // Update vectors for the next iteration
        v_prev = v_curr;
        v_curr = work;
    }

    Ok(x_k)
}

#[cfg(test)]
mod tests {
    use super::*;

    /// Sets up a simple, well-defined test problem using a small, symmetric matrix.
    /// The matrix is a discrete 1D Laplacian, which is symmetric positive-definite.
    fn setup_test_problem() -> (Mat<f64>, Mat<f64>) {
        let a: Mat<f64> = mat![
            [2.0, -1.0, 0.0, 0.0],
            [-1.0, 2.0, -1.0, 0.0],
            [0.0, -1.0, 2.0, -1.0],
            [0.0, 0.0, -1.0, 2.0],
        ];
        let b: Mat<f64> = mat![[1.0], [0.0], [0.0], [0.0]];
        (a, b)
    }

    #[test]
    fn test_lanczos_standard_produces_correct_dimensions() {
        let (a, b) = setup_test_problem();
        let k = 3;

        let result = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();

        assert_eq!(result.v_k.nrows(), a.nrows());
        assert_eq!(result.v_k.ncols(), k);
        assert_eq!(result.t_k.steps_taken, k);
        assert_eq!(result.t_k.alphas.len(), k);
        assert_eq!(result.t_k.betas.len(), k - 1);
    }

    #[test]
    fn test_lanczos_pass_one_produces_correct_dimensions() {
        let (a, b) = setup_test_problem();
        let k = 3;

        let t_k = lanczos_pass_one(&a.as_ref(), b.as_ref(), k).unwrap();

        assert_eq!(t_k.steps_taken, k);
        assert_eq!(t_k.alphas.len(), k);
        assert_eq!(t_k.betas.len(), k - 1);
    }

    #[test]
    fn test_one_pass_and_pass_one_produce_same_tridiagonal() {
        let (a, b) = setup_test_problem();
        let k = 4;

        let standard_result = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();
        let pass_one_result = lanczos_pass_one(&a.as_ref(), b.as_ref(), k).unwrap();

        assert_eq!(standard_result.t_k.alphas, pass_one_result.alphas);
        assert_eq!(standard_result.t_k.betas, pass_one_result.betas);
        assert_eq!(standard_result.t_k.steps_taken, pass_one_result.steps_taken);
    }

    #[test]
    fn test_lanczos_relation_holds() {
        let (a, b) = setup_test_problem();
        let k = 3;

        let result_k = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();
        let mut iter = LanczosIteration::new(&a, b.as_ref(), k + 1).unwrap();
        let mut mem = MemBuffer::new(a.apply_scratch(1, Par::Seq));
        let mut stack = MemStack::new(&mut mem);

        let mut last_step = None;
        for _ in 0..k {
            last_step = iter.next_step(&mut stack);
        }
        let last_step = last_step.unwrap();

        let v_k = result_k.v_k;
        let v_k_plus_1 = iter.v_curr.clone(); // Get the current vector from iterator state
        let beta_k = last_step.beta;

        let t_k_mat = {
            let mut t = Mat::zeros(k, k);
            for i in 0..k {
                t.as_mut()[(i, i)] = result_k.t_k.alphas[i];
            }
            for i in 0..k - 1 {
                t.as_mut()[(i, i + 1)] = result_k.t_k.betas[i];
                t.as_mut()[(i + 1, i)] = result_k.t_k.betas[i];
            }
            t
        };

        // Check A*V_k - V_k*T_k = beta_k * v_{k+1} * e_k^T
        let mut e_k = Mat::zeros(k, 1);
        e_k.as_mut()[(k - 1, 0)] = 1.0;
        let residual = &a * &v_k - &v_k * &t_k_mat;
        let expected_residual = &v_k_plus_1 * e_k.as_ref().adjoint() * Scale(beta_k);

        let diff = &residual - &expected_residual;
        assert!(
            diff.norm_l2() < 1e-14,
            "Lanczos relation A*V_k - V_k*T_k = beta_k * v_{{k+1}} * e_k^T does not hold. Diff norm: {}",
            diff.norm_l2()
        );
    }

    #[test]
    fn test_basis_is_orthonormal() {
        let (a, b) = setup_test_problem();
        let k = 4;
        let result = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();
        let v_k = result.v_k;
        let actual_steps = result.t_k.steps_taken;

        let identity = Mat::<f64>::identity(actual_steps, actual_steps);
        let v_k_adjoint_v_k = v_k.as_ref().adjoint() * v_k.as_ref();

        let diff = &v_k_adjoint_v_k - &identity;
        assert!(
            diff.norm_l2() < 1e-14,
            "Lanczos basis vectors are not orthonormal. Diff norm: {}",
            diff.norm_l2()
        );
    }

    #[test]
    fn test_two_pass_reconstruction() {
        let (a, b) = setup_test_problem();
        let k = 3;

        // Perform standard Lanczos to get the reference V_k
        let standard_result = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();
        let v_k_ref = standard_result.v_k;
        let actual_steps = standard_result.t_k.steps_taken;

        // Perform two-pass algorithm
        let t_k = lanczos_pass_one(&a.as_ref(), b.as_ref(), k).unwrap();
        assert_eq!(actual_steps, t_k.steps_taken);

        // Create an arbitrary coefficient vector y_k
        let mut y_k = Mat::<f64>::zeros(actual_steps, 1);
        for i in 0..actual_steps {
            y_k.as_mut()[(i, 0)] = 0.1 * (i + 1) as f64; // e.g., [0.1, 0.2, 0.3]
        }

        // Reconstruct the solution using the second pass
        let x_k_two_pass = lanczos_pass_two(&a.as_ref(), b.as_ref(), &t_k, y_k.as_ref()).unwrap();

        // Compute the expected solution from the standard method
        let x_k_expected = &v_k_ref * &y_k;

        let diff = &x_k_two_pass - &x_k_expected;
        assert!(
            diff.norm_l2() < 1e-14,
            "Two-pass reconstruction does not match standard method. Diff norm: {}",
            diff.norm_l2()
        );
    }

    #[test]
    fn test_breakdown_scenario() {
        // A is diagonal, and b is an eigenvector. The Krylov subspace is of dimension 1.
        let a: Mat<f64> = mat![[2.0, 0.0], [0.0, 3.0]];
        let b: Mat<f64> = mat![[1.0], [0.0]];
        let k = 2; // Request 2 iterations, but it should stop after 1.

        let result = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();

        // After 1 iteration with an eigenvector, breakdown should occur.
        assert_eq!(result.t_k.steps_taken, 1);
        assert_eq!(result.t_k.alphas.len(), 1);
        assert_eq!(result.t_k.betas.len(), 0);
        assert_eq!(result.v_k.ncols(), 1);

        // The alpha should be the eigenvalue (2.0).
        assert!((result.t_k.alphas[0] - 2.0).abs() < 1e-14);

        let t_k_pass_one = lanczos_pass_one(&a.as_ref(), b.as_ref(), k).unwrap();
        assert_eq!(t_k_pass_one.steps_taken, 1);
        assert_eq!(t_k_pass_one.alphas.len(), 1);
        assert_eq!(t_k_pass_one.betas.len(), 0);
        assert!((t_k_pass_one.alphas[0] - 2.0).abs() < 1e-14);
    }

    #[test]
    fn test_zero_vector_input_returns_error_iterator() {
        let a: Mat<f64> = Mat::identity(2, 2);
        let b: Mat<f64> = Mat::zeros(2, 1);

        assert!(LanczosIteration::new(&a, b.as_ref(), 2).is_err());
    }

    #[test]
    fn test_zero_vector_input_returns_error() {
        let a: Mat<f64> = Mat::identity(2, 2);
        let b: Mat<f64> = Mat::zeros(2, 1);

        assert!(lanczos_standard(&a, b.as_ref(), 2).is_err());
        assert!(lanczos_pass_one(&a, b.as_ref(), 2).is_err());
        let t_k = Tridiagonal {
            alphas: vec![],
            betas: vec![],
            steps_taken: 0,
        };
        let y_k: Mat<f64> = Mat::zeros(0, 1);
        assert!(lanczos_pass_two(&a, b.as_ref(), &t_k, y_k.as_ref()).is_err());
    }
}
