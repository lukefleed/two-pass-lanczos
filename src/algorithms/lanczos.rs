//! This module provides implementations of the symmetric Lanczos algorithm.
//!
//! It includes the standard one-pass algorithm, which generates and stores the basis
//! vectors, and a memory-efficient two-pass variant that regenerates the basis vectors
//! in a second pass to avoid storing them. The implementations are generic and
//! operate on any type that implements the `faer::operator::LinOp` trait.

use crate::error::{LanczosError, LanczosErrorKind};
use faer::{
    Par, Scale,
    dyn_stack::{MemBuffer, MemStack},
    matrix_free::LinOp,
    prelude::*,
    traits::{ComplexField, RealField, num_traits::Zero},
};

/// Represents the real, symmetric, tridiagonal matrix T_k generated by the Lanczos process.
///
/// The matrix is stored implicitly by its diagonal and off-diagonal elements.
#[derive(Debug, Clone)]
pub struct Tridiagonal<R: RealField> {
    /// The diagonal elements of the tridiagonal matrix (α_j).
    pub alphas: Vec<R>,
    /// The super/sub-diagonal elements of the tridiagonal matrix (β_j).
    /// `betas[j]` corresponds to β_{j+1}.
    pub betas: Vec<R>,
    /// The actual number of steps performed before breakdown or completion.
    pub steps_taken: usize,
}

/// Contains the complete output of the standard one-pass Lanczos algorithm.
#[derive(Debug)]
pub struct LanczosOutput<T: ComplexField> {
    /// The matrix V_k whose columns are the orthonormal Lanczos basis vectors.
    pub v_k: Mat<T>,
    /// The tridiagonal matrix T_k, which is the projection of the operator onto the Krylov subspace.
    pub t_k: Tridiagonal<T::Real>,
}

/// Private struct representing the output of a single step of the Lanczos iteration.
struct LanczosStep<T: ComplexField> {
    /// The newly computed Lanczos vector, v_{j+1}.
    v_next: Mat<T>,
    /// The diagonal element α_j.
    alpha: T::Real,
    /// The off-diagonal element β_j.
    beta: T::Real,
}

/// Private struct that encapsulates the state of the Lanczos iteration.
///
/// This struct implements the `Iterator` trait to provide a clean, stateful
/// representation of the Lanczos recurrence, which can be consumed by different
/// algorithm implementations.
struct LanczosIteration<'a, T: ComplexField, O: LinOp<T>> {
    /// A reference to the linear operator.
    operator: &'a O,
    /// The previous Lanczos vector, v_{j-1}.
    v_prev: Mat<T>,
    /// The current Lanczos vector, v_j.
    v_curr: Mat<T>,
    /// The previous beta coefficient, β_{j-1}.
    beta_prev: T::Real,
    /// The current iteration number.
    k: usize,
    /// The maximum number of iterations to perform.
    max_k: usize,
}

impl<'a, T: ComplexField, O: LinOp<T>> LanczosIteration<'a, T, O>
where
    T::Real: RealField + Zero,
{
    /// Creates a new `LanczosIteration` instance.
    ///
    /// # Panics
    /// Panics if the input vector `b` is a zero vector.
    fn new(operator: &'a O, b: MatRef<'_, T>, max_k: usize) -> Self {
        let b_norm = b.norm_l2();
        if b_norm.is_zero() {
            // The Lanczos process is not defined for a zero starting vector.
            // Using a panic here as it represents a logical error in the calling code.
            panic!("Input vector `b` must not be a zero vector.");
        }

        let mut v1 = Mat::zeros(b.nrows(), 1);
        v1.as_mut().copy_from(&b);
        let inv_norm = T::from_real_impl(&T::Real::recip_impl(&b_norm));
        v1 = &v1 * Scale(inv_norm);

        Self {
            operator,
            v_prev: Mat::zeros(b.nrows(), 1),
            v_curr: v1,
            beta_prev: T::Real::zero_impl(),
            k: 0,
            max_k,
        }
    }

    /// Performs the next step of the Lanczos iteration.
    fn next_step(&mut self, stack: &mut MemStack) -> Option<LanczosStep<T>> {
        if self.k >= self.max_k {
            return None;
        }

        // Apply the operator A * v_curr
        let mut w = Mat::<T>::zeros(self.operator.nrows(), 1);
        self.operator
            .apply(w.as_mut(), self.v_curr.as_ref(), Par::Seq, stack);

        // Orthogonalize against previous vector: w = w - beta_{j-1} * v_{j-1}
        let temp1 = &self.v_prev * Scale(T::from_real_impl(&self.beta_prev));
        w = &w - &temp1;

        // Compute alpha_j = v_j^H * w
        let alpha = T::real_part_impl(&(self.v_curr.as_ref().adjoint() * w.as_ref())[(0, 0)]);

        // Orthogonalize against current vector: w = w - alpha_j * v_j
        let temp2 = &self.v_curr * Scale(T::from_real_impl(&alpha));
        w = &w - &temp2;

        // Compute beta_j = ||w||
        let beta = w.as_ref().norm_l2();

        self.k += 1;

        // Check for breakdown
        if beta <= T::Real::zero_impl() {
            return None;
        }

        // Store beta before moving it
        let beta_for_result = T::Real::copy_impl(&beta);

        // Normalize: v_{j+1} = w / beta_j
        let inv_beta = T::from_real_impl(&T::Real::recip_impl(&beta));
        let v_next = &w * Scale(inv_beta);

        self.v_prev = core::mem::replace(&mut self.v_curr, v_next.clone());
        self.beta_prev = beta;

        Some(LanczosStep {
            v_next,
            alpha,
            beta: beta_for_result,
        })
    }
}

/// Performs the standard one-pass symmetric Lanczos algorithm.
///
/// This function executes `k` steps of the Lanczos process, storing the generated
/// basis vectors in the columns of the matrix `v_k`.
///
/// # Arguments
/// * `operator`: A linear operator that implements `faer::operator::LinOp`.
/// * `b`: The starting vector. Must not be a zero vector.
/// * `k`: The number of iterations to perform.
///
/// # Returns
/// A `Result` containing the `LanczosOutput` on success, or a `LanczosError` on failure.
pub fn lanczos_standard<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    k: usize,
) -> Result<LanczosOutput<T>, LanczosError>
where
    T::Real: RealField + Zero,
{
    if b.norm_l2().is_zero() {
        return Err(LanczosErrorKind::InputError(
            "The initial vector `b` must not be a zero vector.".to_string(),
        )
        .into());
    }

    let mut v_k = Mat::<T>::zeros(operator.nrows(), k);
    let mut alphas = Vec::with_capacity(k);
    let mut betas = Vec::with_capacity(k - 1);

    let mut lanczos_iter = LanczosIteration::new(operator, b, k);
    v_k.col_mut(0)
        .copy_from(lanczos_iter.v_curr.as_ref().col(0));

    let mut steps_taken = 0;
    let mut mem = MemBuffer::new(operator.apply_scratch(1, Par::Seq));
    let mut stack = MemStack::new(&mut mem);

    for i in 0..k {
        if let Some(step) = lanczos_iter.next_step(&mut stack) {
            alphas.push(step.alpha);
            if i < k - 1 {
                betas.push(step.beta);
            }
            if i < k - 1 {
                v_k.col_mut(i + 1).copy_from(step.v_next.as_ref().col(0));
            }
            steps_taken += 1;
        } else {
            // Breakdown occurred
            break;
        }
    }

    Ok(LanczosOutput {
        v_k: v_k.as_ref().get(.., 0..steps_taken).to_owned(),
        t_k: Tridiagonal {
            alphas,
            betas,
            steps_taken,
        },
    })
}

/// Performs the first pass of the two-pass Lanczos algorithm.
///
/// This pass computes the coefficients of the tridiagonal matrix `T_k` without storing
/// the Lanczos basis vectors, resulting in an O(n) memory footprint.
///
/// # Arguments
/// * `operator`: A linear operator that implements `faer::operator::LinOp`.
/// * `b`: The starting vector. Must not be a zero vector.
/// * `k`: The number of iterations to perform.
///
/// # Returns
/// A `Result` containing the `Tridiagonal` matrix data on success, or a `LanczosError`.
pub fn lanczos_pass_one<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    k: usize,
) -> Result<Tridiagonal<T::Real>, LanczosError>
where
    T::Real: RealField + Zero,
{
    if b.norm_l2().is_zero() {
        return Err(LanczosErrorKind::InputError(
            "The initial vector `b` must not be a zero vector.".to_string(),
        )
        .into());
    }

    let mut alphas = Vec::with_capacity(k);
    let mut betas = Vec::with_capacity(k - 1);

    let mut lanczos_iter = LanczosIteration::new(operator, b, k);

    let mut steps_taken = 0;
    let mut mem = MemBuffer::new(operator.apply_scratch(1, Par::Seq));
    let mut stack = MemStack::new(&mut mem);

    for i in 0..k {
        if let Some(step) = lanczos_iter.next_step(&mut stack) {
            alphas.push(step.alpha);
            if i < k - 1 {
                betas.push(step.beta);
            }
            steps_taken += 1;
        } else {
            // Breakdown
            break;
        }
    }

    Ok(Tridiagonal {
        alphas,
        betas,
        steps_taken,
    })
}

/// Performs the second pass of the two-pass Lanczos algorithm.
///
/// This pass reconstructs the solution vector `x_k = V_k * y_k` by regenerating the
/// Lanczos basis vectors on-the-fly using the coefficients from the first pass.
///
/// # Arguments
/// * `operator`: A linear operator that implements `faer::operator::LinOp`.
/// * `b`: The original starting vector.
/// * `t_k`: The tridiagonal matrix data generated by `lanczos_pass_one`.
/// * `y_k`: The coefficient vector, typically computed as `f(T_k) * e_1 * ||b||`.
///
/// # Returns
/// A `Result` containing the final approximate solution vector `x_k`.
pub fn lanczos_pass_two<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    t_k: &Tridiagonal<T::Real>,
    y_k: MatRef<'_, T>,
) -> Result<Mat<T>, LanczosError>
where
    T::Real: RealField + Zero,
{
    if b.norm_l2().is_zero() {
        return Err(LanczosErrorKind::InputError(
            "The initial vector `b` must not be a zero vector.".to_string(),
        )
        .into());
    }
    if t_k.steps_taken != y_k.nrows() {
        return Err(LanczosErrorKind::DimensionMismatch {
            operator_cols: t_k.steps_taken,
            vector_rows: y_k.nrows(),
        }
        .into());
    }
    if t_k.steps_taken == 0 {
        return Ok(Mat::zeros(b.nrows(), 1));
    }

    let b_norm = b.norm_l2();
    let mut v_prev = Mat::<T>::zeros(b.nrows(), 1);
    let mut v_curr = Mat::<T>::zeros(b.nrows(), 1);
    v_curr.as_mut().copy_from(&b);
    let inv_norm = T::from_real_impl(&T::Real::recip_impl(&b_norm));
    v_curr = &v_curr * Scale(inv_norm);

    // Initialize the solution with the first term: x_k = y_1 * v_1
    let mut x_k = &v_curr * Scale(T::copy_impl(&y_k[(0, 0)]));

    let mut mem = MemBuffer::new(operator.apply_scratch(1, Par::Seq));
    let mut stack = MemStack::new(&mut mem);

    for j in 0..t_k.steps_taken - 1 {
        // Regenerate v_{j+1} using the stored coefficients.
        let alpha_j = T::Real::copy_impl(&t_k.alphas[j]);
        let beta_j = T::Real::copy_impl(&t_k.betas[j]);
        let beta_prev = if j == 0 {
            T::Real::zero_impl()
        } else {
            T::Real::copy_impl(&t_k.betas[j - 1])
        };

        // Apply operator: w = A * v_curr
        let mut w = Mat::<T>::zeros(operator.nrows(), 1);
        operator.apply(w.as_mut(), v_curr.as_ref(), Par::Seq, &mut stack);

        // Orthogonalize: w = w - alpha_j * v_curr - beta_prev * v_prev
        let temp1 = &v_curr * Scale(T::from_real_impl(&alpha_j));
        let temp2 = &v_prev * Scale(T::from_real_impl(&beta_prev));
        w = &w - &temp1 - &temp2;

        // Normalize: v_next = w / beta_j
        let inv_beta = T::from_real_impl(&T::Real::recip_impl(&beta_j));
        let v_next = &w * Scale(inv_beta);

        // Accumulate into the solution vector: x_k <- x_k + y_{j+1} * v_{j+1}
        x_k = &x_k + &(&v_next * Scale(T::copy_impl(&y_k[(j + 1, 0)])));

        // Update vectors for the next iteration
        v_prev = v_curr;
        v_curr = v_next;
    }

    Ok(x_k)
}

#[cfg(test)]
mod tests {
    use super::*;
    use faer::assert_matrix_eq;

    /// A simple test case with a diagonal matrix. The Lanczos process should
    /// produce a tridiagonal matrix T_k whose eigenvalues are approximations
    /// of the eigenvalues of A.
    fn setup_test_problem() -> (Mat<f64>, Mat<f64>) {
        let a: Mat<f64> = mat![
            [2.0, -1.0, 0.0, 0.0],
            [-1.0, 2.0, -1.0, 0.0],
            [0.0, -1.0, 2.0, -1.0],
            [0.0, 0.0, -1.0, 2.0],
        ];
        let b: Mat<f64> = mat![[1.0], [0.0], [0.0], [0.0]];
        (a, b)
    }

    #[test]
    fn test_lanczos_standard_produces_correct_dimensions() {
        let (a, b) = setup_test_problem();
        let k = 3;

        let result = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();

        assert_eq!(result.v_k.nrows(), a.nrows());
        assert_eq!(result.v_k.ncols(), k); // v1, ..., vk
        assert_eq!(result.t_k.steps_taken, k);
        assert_eq!(result.t_k.alphas.len(), k);
        assert_eq!(result.t_k.betas.len(), k - 1);
    }

    #[test]
    fn test_lanczos_pass_one_produces_correct_dimensions() {
        let (a, b) = setup_test_problem();
        let k = 3;

        let t_k = lanczos_pass_one(&a.as_ref(), b.as_ref(), k).unwrap();

        assert_eq!(t_k.steps_taken, k);
        assert_eq!(t_k.alphas.len(), k);
        assert_eq!(t_k.betas.len(), k - 1);
    }

    #[test]
    fn test_one_pass_and_pass_one_produce_same_tridiagonal() {
        let (a, b) = setup_test_problem();
        let k = 4;

        let standard_result = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();
        let pass_one_result = lanczos_pass_one(&a.as_ref(), b.as_ref(), k).unwrap();

        assert_eq!(standard_result.t_k.alphas, pass_one_result.alphas);
        assert_eq!(standard_result.t_k.betas, pass_one_result.betas);
        assert_eq!(standard_result.t_k.steps_taken, pass_one_result.steps_taken);
    }

    #[test]
    fn test_lanczos_relation_holds() {
        let (a, b) = setup_test_problem();
        let k = 3;

        let result_k = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();
        let mut iter = LanczosIteration::new(&a, b.as_ref(), k + 1);
        let mut mem = MemBuffer::new(a.apply_scratch(1, Par::Seq));
        let mut stack = MemStack::new(&mut mem);

        let mut last_step = None;
        for _ in 0..k {
            last_step = iter.next_step(&mut stack);
        }
        let last_step = last_step.unwrap();

        let v_k = result_k.v_k;
        let v_k_plus_1 = last_step.v_next;
        let beta_k = last_step.beta;

        let t_k_mat = {
            let mut t = Mat::zeros(k, k);
            for i in 0..k {
                t.write(i, i, result_k.t_k.alphas[i]);
            }
            for i in 0..k - 1 {
                t.write(i, i + 1, result_k.t_k.betas[i]);
                t.write(i + 1, i, result_k.t_k.betas[i]);
            }
            t
        };

        // Check A*V_k - V_k*T_k = beta_k * v_{k+1} * e_k^T
        let mut e_k_t = Mat::zeros(k, 1);
        e_k_t.write(k - 1, 0, 1.0);
        let residual = &a * &v_k - &v_k * &t_k_mat;
        let expected_residual = &v_k_plus_1 * e_k_t.as_ref().adjoint() * scale(beta_k);

        assert_matrix_eq!(residual, expected_residual, comp = abs, tol = 1e-14);
    }

    #[test]
    fn test_basis_is_orthonormal() {
        let (a, b) = setup_test_problem();
        let k = 4;
        let result = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();
        let v_k = result.v_k;

        let identity = Mat::<f64>::identity(k, k);
        let v_k_adjoint_v_k = v_k.adjoint() * v_k;

        assert_matrix_eq!(v_k_adjoint_v_k, identity, comp = abs, tol = 1e-14);
    }

    #[test]
    fn test_two_pass_reconstruction() {
        let (a, b) = setup_test_problem();
        let k = 4;

        // Perform standard Lanczos to get the reference V_k
        let standard_result = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();
        let v_k_ref = standard_result.v_k;

        // Perform two-pass algorithm
        let t_k = lanczos_pass_one(&a.as_ref(), b.as_ref(), k).unwrap();

        // Create a dummy coefficient vector y_k
        let y_k: Mat<f64> = mat![[0.1], [0.2], [0.3], [0.4]];

        // Reconstruct the solution
        let x_k_two_pass = lanczos_pass_two(&a.as_ref(), b.as_ref(), &t_k, y_k.as_ref()).unwrap();

        // Compute the expected solution from the standard method
        let x_k_expected = &v_k_ref * &y_k;

        assert_matrix_eq!(x_k_two_pass, x_k_expected, comp = abs, tol = 1e-14);
    }

    #[test]
    fn test_breakdown_scenario() {
        // A is diagonal, and b is an eigenvector. The Krylov subspace is of dimension 1.
        let a: Mat<f64> = mat![[2.0, 0.0], [0.0, 3.0]];
        let b: Mat<f64> = mat![[1.0], [0.0]];
        let k = 2; // Request 2 iterations, but it should stop after 1.

        let result = lanczos_standard(&a.as_ref(), b.as_ref(), k).unwrap();
        assert_eq!(result.t_k.steps_taken, 1);
        assert_eq!(result.t_k.alphas.len(), 1);
        assert_eq!(result.t_k.betas.len(), 0);
        assert_eq!(result.v_k.ncols(), 1);

        let t_k_pass_one = lanczos_pass_one(&a.as_ref(), b.as_ref(), k).unwrap();
        assert_eq!(t_k_pass_one.steps_taken, 1);
        assert_eq!(t_k_pass_one.alphas.len(), 1);
        assert_eq!(t_k_pass_one.betas.len(), 0);
    }

    #[test]
    #[should_panic(expected = "Input vector `b` must not be a zero vector.")]
    fn test_zero_vector_input_panics_iterator() {
        let a: Mat<f64> = Mat::identity(2, 2);
        let b: Mat<f64> = Mat::zeros(2, 1);
        let _ = LanczosIteration::new(&a, b.as_ref(), 2);
    }

    #[test]
    fn test_zero_vector_input_returns_error() {
        let a: Mat<f64> = Mat::identity(2, 2);
        let b: Mat<f64> = Mat::zeros(2, 1);

        assert!(lanczos_standard(&a, b.as_ref(), 2).is_err());
        assert!(lanczos_pass_one(&a, b.as_ref(), 2).is_err());
        let t_k = Tridiagonal {
            alphas: vec![],
            betas: vec![],
            steps_taken: 0,
        };
        let y_k: Mat<f64> = Mat::zeros(0, 1);
        assert!(lanczos_pass_two(&a, b.as_ref(), &t_k, y_k.as_ref()).is_err());
    }
}
