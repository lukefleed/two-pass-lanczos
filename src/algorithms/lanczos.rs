//! Implements the symmetric Lanczos algorithm for Krylov subspace methods.
//!
//! This module provides two primary implementations for computing the action of a matrix
//! function on a vector, $f(\mathbf{A})\mathbf{b}$. The core idea is to project the
//! high-dimensional operator $\mathbf{A}$ onto a low-dimensional Krylov subspace,
//! yielding a small, symmetric tridiagonal matrix $\mathbf{T}_k$.
//!
//! The module includes:
//! 1.  A **standard one-pass algorithm**, which generates and stores the orthonormal basis
//!     vectors $\mathbf{V}_k$ of the Krylov subspace. This approach is conceptually simple
//!     but incurs an $O(nk)$ memory cost.
//! 2.  A **memory-efficient two-pass variant**, which avoids storing the basis. It first
//!     computes the scalar coefficients of $\mathbf{T}_k$ and then regenerates the basis
//!     vectors on-the-fly in a second pass to synthesize the final solution.
//!
//! The implementations are generic over any type that implements the [`faer::matrix_free::LinOp`]
//! trait. This matrix-free design allows the algorithms to operate on any linear operator,
//! not just explicit matrices, which is crucial for applications where $\mathbf{A}$ is defined
//! implicitly (e.g., via a function call). The use of [`MemStack`] provides efficient stack-based
//! memory management for temporary workspaces, minimizing heap allocation overhead.

use crate::error::{LanczosError, LanczosErrorKind};
use faer::traits::math_utils::{add, mul, sub};
use faer::{
    Par,
    dyn_stack::MemStack,
    matrix_free::LinOp,
    prelude::*,
    traits::{ComplexField, RealField},
};

/// A read-only, non-owning view of the tridiagonal matrix generated by the Lanczos process.
///
/// This struct provides zero-allocation access to the raw tridiagonal matrix data
/// by referencing existing slices. Its primary use is in callbacks for inspecting the
/// algorithm's state without incurring the performance penalty of data duplication or
/// cache-unfriendly pointer indirection.
#[derive(Debug)]
pub struct TridiagonalSystemView<'a, R: RealField> {
    /// The diagonal elements of the tridiagonal matrix, corresponding to the
    /// sequence of $\alpha_j$ coefficients.
    pub alphas: &'a [R],
    /// The super/sub-diagonal elements, corresponding to the sequence of $\beta_j$
    /// coefficients.
    pub betas: &'a [R],
    /// The number of iterations completed, which defines the actual dimension
    /// of the system, especially in cases of early termination due to breakdown.
    pub steps_taken: usize,
}

/// A callback function invoked at each step of the Lanczos iteration.
///
/// This provides a hook for monitoring convergence, implementing custom termination
/// criteria, or performing other diagnostics.
///
/// # Arguments
/// * `k`: The current iteration number (1-based).
/// * `v_k`: An immutable view of the $n \times k$ basis matrix $\mathbf{V}_k = [\mathbf{v}_1, \dots, \mathbf{v}_k]$
///   generated so far.
/// * `t_k_view`: A non-owning view of the tridiagonal matrix $\mathbf{T}_k$.
///
/// # Returns
/// `true` to continue the iteration, `false` to request an early stop.
pub type LanczosCallback<T> = dyn for<'a> FnMut(
    usize,
    MatRef<'a, T>,
    &'a TridiagonalSystemView<'a, <T as ComplexField>::Real>,
) -> bool;

/// Contains the scalar data defining the low-dimensional projection of the operator.
///
/// This struct holds all data necessary to define the tridiagonal system $\mathbf{T}_k$
/// and is the complete output of the first pass of the two-pass algorithm. It is
/// designed to be lightweight and cloneable.
#[derive(Debug, Clone)]
pub struct LanczosDecomposition<R: RealField> {
    /// The diagonal elements of the tridiagonal matrix ($\alpha_j$).
    pub alphas: Vec<R>,
    /// The super/sub-diagonal elements of the tridiagonal matrix ($\beta_j$).
    /// The element `betas[j-1]` corresponds to $\beta_j$ for $j = 1, \dots, \text{steps\_taken}-1$.
    /// The vector length is always `steps_taken - 1`.
    pub betas: Vec<R>,
    /// The actual number of steps performed before breakdown or completion. This may be
    /// less than the requested number of iterations.
    pub steps_taken: usize,
    /// The L2 norm of the initial vector, $\|\mathbf{b}\|_2$. This value is pre-computed and
    /// stored to avoid recomputation and is required for the final scaling of the
    /// solution vector $\mathbf{x}_k = \mathbf{V}_k f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2$.
    pub b_norm: R,
}

/// Contains the complete output of the standard one-pass Lanczos algorithm.
///
/// This structure holds both the orthonormal basis vectors and the full scalar
/// decomposition, representing the complete state of the Lanczos process after $k$ steps.
#[derive(Debug)]
pub struct LanczosOutput<T: ComplexField> {
    /// The matrix $\mathbf{V}_k \in \mathbb{C}^{n \times k}$ whose columns are the orthonormal
    /// Lanczos basis vectors, $[\mathbf{v}_1, \dots, \mathbf{v}_k]$.
    /// This is the structure that incurs the $O(nk)$ memory cost.
    pub v_k: Mat<T>,
    /// The scalar data from the Lanczos process, including $\mathbf{T}_k$ and $\|\mathbf{b}\|_2$.
    pub decomposition: LanczosDecomposition<T::Real>,
}

/// Contains the output of the second pass, including the regenerated basis.
///
/// This struct is exposed only for testing purposes (via `cfg(test)`) to allow for a direct
/// norm comparison between the stored basis from [`lanczos_standard`] and the
/// regenerated basis.
#[derive(Debug)]
pub struct LanczosPassTwoOutput<T: ComplexField> {
    /// The final approximate solution vector $\mathbf{x}_k$.
    pub x_k: Mat<T>,
    /// The regenerated basis matrix $\mathbf{V}'_k$.
    pub v_k: Mat<T>,
}

/// Computes the tolerance for breakdown detection based on machine epsilon.
///
/// This provides better numerical robustness than hardcoded tolerances.
fn breakdown_tolerance<T: RealField>() -> T {
    // A small multiple of machine epsilon is a standard choice for breakdown detection.
    T::from_f64_impl(f64::EPSILON * 1000.0)
}

/// Performs a single, fully orthogonalized step of the Lanczos recurrence relation.
///
/// This function implements the core three-term recurrence:
/// $\beta_j \mathbf{v}_{j+1} = \mathbf{A}\mathbf{v}_j - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}$.
///
/// The implementation follows the standard formulation, ensuring that the newly
/// computed (unnormalized) vector is orthogonal to the two preceding basis vectors.
/// The result is written to a pre-allocated mutable view `w` to avoid heap allocations
/// within the iterative loop.
///
/// # Arguments
/// * `operator`: The linear operator $\mathbf{A}$.
/// * `w`: A pre-allocated mutable matrix view for the output vector $\mathbf{w} = \beta_j \mathbf{v}_{j+1}$.
/// * `v_curr`: The current Lanczos vector $\mathbf{v}_j$.
/// * `v_prev`: The previous Lanczos vector $\mathbf{v}_{j-1}$.
/// * `beta_prev`: The previous off-diagonal coefficient $\beta_{j-1}$.
/// * `stack`: A [`MemStack`] for temporary allocations required by the operator's `apply` method.
///
/// # Returns
/// A tuple containing $(\alpha_j, \text{Option}<\beta_j>)$. A [`None`] value for $\beta_j$ indicates
/// that a numerical breakdown has occurred ($\beta_j$ is numerically zero), and the iteration
/// should terminate. This happens when the Krylov subspace becomes invariant under $\mathbf{A}$.
fn lanczos_recurrence_step<T: ComplexField, O: LinOp<T>>(
    operator: &O,
    mut w: MatMut<'_, T>,
    v_curr: MatRef<'_, T>,
    v_prev: MatRef<'_, T>,
    beta_prev: T::Real,
    stack: &mut MemStack,
) -> (T::Real, Option<T::Real>) {
    // 1. Apply the operator: w = A * v_curr. This is typically the most
    // computationally intensive part of the step.
    operator.apply(w.rb_mut(), v_curr, Par::Seq, stack);

    // 2. First orthogonalization step (against v_{j-1}).
    // This computes w <- w - \beta_{j-1} * v_{j-1} in-place.
    // The use of `zip!` ensures that this loop can be autovectorized by the
    // compiler
    let beta_prev_scaled = T::from_real_impl(&beta_prev);
    zip!(w.rb_mut(), v_prev).for_each(|unzip!(w_i, v_prev_i)| {
        *w_i = sub(w_i, &mul(&beta_prev_scaled, v_prev_i));
    });

    // 3. Compute the diagonal element \alpha_j = v_j^H * w.
    // At this stage, w = A*v_j - \beta_{j-1}*v_{j-1}, which is the
    // intermediate vector for computing \alpha_j. Since A is Hermitian, \alpha_j is real.
    let alpha = T::real_part_impl(&(v_curr.adjoint() * w.rb())[(0, 0)]);

    // 4. Second orthogonalization step (against v_j).
    // This computes w <- w - \alpha_j * v_j in-place.
    let alpha_scaled = T::from_real_impl(&alpha);
    zip!(w.rb_mut(), v_curr).for_each(|unzip!(w_i, v_curr_i)| {
        *w_i = sub(w_i, &mul(&alpha_scaled, v_curr_i));
    });

    // 5. Compute the off-diagonal element \beta_j = ||w||_2.
    // The vector w now holds the unnormalized next Lanczos vector.
    let beta = w.rb().norm_l2();

    // 6. Check for numerical breakdown. If \beta_j is close to zero, the Krylov
    // subspace is (numerically) invariant under A, and the iteration must stop.
    let tolerance = breakdown_tolerance::<T::Real>();
    if beta <= tolerance {
        (alpha, None)
    } else {
        (alpha, Some(beta))
    }
}

/// A lightweight struct to hold the scalar results of a single Lanczos step.
struct LanczosStep<T: ComplexField> {
    /// The diagonal element $\alpha_j$.
    alpha: T::Real,
    /// The off-diagonal element $\beta_j$.
    beta: T::Real,
}

/// A private struct that encapsulates the state of the Lanczos iteration.
///
/// This struct provides a clean, stateful representation of the Lanczos recurrence,
/// abstracting away the low-level vector manipulations. It is designed as an iterator-like
/// object that can be consumed by different high-level algorithm implementations (e.g.,
/// one-pass vs. two-pass). It manages its own work vectors to avoid repeated heap
/// allocations in the main iterative loop. The use of `Mat<T>` instead of [`MatMut`]
/// for vectors means that this struct takes ownership of the vector data.
struct LanczosIteration<'a, T: ComplexField, O: LinOp<T>> {
    /// A reference to the linear operator.
    operator: &'a O,
    /// The previous Lanczos vector, $\mathbf{v}_{j-1}$.
    v_prev: Mat<T>,
    /// The current Lanczos vector, $\mathbf{v}_j$.
    v_curr: Mat<T>,
    /// A reusable work vector for intermediate computations, primarily to hold $\mathbf{A}\mathbf{v}_j$.
    work: Mat<T>,
    /// The previous beta coefficient, $\beta_{j-1}$.
    beta_prev: T::Real,
    /// The current iteration number (0-indexed internally).
    k: usize,
    /// The maximum number of iterations to perform.
    max_k: usize,
}

impl<'a, T: ComplexField, O: LinOp<T>> LanczosIteration<'a, T, O>
where
    T::Real: RealField,
{
    /// Creates a new [`LanczosIteration`] instance and prepares the initial state.
    ///
    /// # Arguments
    /// * `operator`: The linear operator to be used.
    /// * `b`: The initial vector.
    /// * `max_k`: The maximum number of iterations.
    /// * `b_norm`: The pre-computed L2 norm of `b`.
    ///
    /// # Returns
    /// A [`Result`] containing the new instance or a [`LanczosError`] if the input vector is zero.
    fn new(
        operator: &'a O,
        b: MatRef<'_, T>,
        max_k: usize,
        b_norm: T::Real,
    ) -> Result<Self, LanczosError> {
        let zero_threshold = breakdown_tolerance::<T::Real>();
        if b_norm <= zero_threshold {
            return Err(LanczosErrorKind::InputError(
                "Input vector `b` must not be a zero vector.".to_string(),
            )
            .into());
        }

        // Normalize the initial vector efficiently using the pre-computed norm.
        // This avoids a second norm calculation.
        let inv_norm = T::from_real_impl(&T::Real::recip_impl(&b_norm));
        let v1 = b * Scale(inv_norm);

        Ok(Self {
            operator,
            v_prev: Mat::zeros(b.nrows(), 1),
            v_curr: v1,
            work: Mat::zeros(b.nrows(), 1),
            beta_prev: T::Real::zero_impl(),
            k: 0,
            max_k,
        })
    }

    /// Performs the next step of the Lanczos iteration and updates the internal state.
    fn next_step(&mut self, stack: &mut MemStack) -> Option<LanczosStep<T>> {
        if self.k >= self.max_k {
            return None;
        }

        // Execute the core recurrence using the pre-allocated work vector.
        let (alpha, beta_option) = lanczos_recurrence_step(
            self.operator,
            self.work.as_mut(),
            self.v_curr.as_ref(),
            self.v_prev.as_ref(),
            T::Real::copy_impl(&self.beta_prev),
            stack,
        );

        self.k += 1;

        match beta_option {
            Some(beta) => {
                // Normalize the next Lanczos vector in-place: v_{j+1} = work / \beta_j
                let inv_beta = T::from_real_impl(&T::Real::recip_impl(&beta));
                zip!(self.work.as_mut()).for_each(|unzip!(w_i)| {
                    *w_i = mul(w_i, &inv_beta);
                });

                // Update state for the next iteration using move semantics.
                // Swapping vectors is a zero-cost operation that avoids cloning large amounts
                // of data, significantly improving performance by reducing memory traffic.
                // The logical flow is: v_prev gets v_curr's data, v_curr gets the newly computed
                // vector from `work`, and `work` gets the old v_prev's allocation to be reused.
                core::mem::swap(&mut self.v_prev, &mut self.v_curr);
                core::mem::swap(&mut self.v_curr, &mut self.work);
                self.beta_prev = T::Real::copy_impl(&beta);

                Some(LanczosStep {
                    alpha,
                    beta: T::Real::copy_impl(&beta),
                })
            }
            None => {
                // Breakdown occurred. The iteration cannot continue. Return the computed alpha
                // and a zero beta to signal termination to the caller.
                Some(LanczosStep {
                    alpha,
                    beta: T::Real::zero_impl(),
                })
            }
        }
    }
}

/// Performs the standard one-pass symmetric Lanczos algorithm.
///
/// This function executes up to `k` steps of the Lanczos process to generate an
/// orthonormal basis $\mathbf{V}_k$ for the Krylov subspace $\mathcal{K}_k(\mathbf{A}, \mathbf{b})$.
/// It stores the generated basis vectors in the columns of the matrix `v_k`, leading to
/// an $O(nk)$ memory complexity.
///
/// An optional callback function can be provided to inspect the algorithm's state at
/// each iteration, allowing for custom convergence monitoring.
///
/// # Arguments
/// * `operator`: A linear operator implementing [`faer::matrix_free::LinOp`].
/// * `b`: The starting vector. Must not be a zero vector.
/// * `k`: The maximum number of iterations to perform.
/// * `stack`: A [`MemStack`] for temporary allocations.
/// * `callback`: An optional mutable reference to a callback function invoked at each iteration.
///
/// # Returns
/// A [`Result`] containing the [`LanczosOutput`] on success, or a [`LanczosError`] on failure.
/// The output includes the basis matrix $\mathbf{V}_k$ and the scalar decomposition
/// defining the tridiagonal matrix $\mathbf{T}_k$.
pub fn lanczos_standard<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    k: usize,
    stack: &mut MemStack,
    mut callback: Option<&mut LanczosCallback<T>>,
) -> Result<LanczosOutput<T>, LanczosError>
where
    T::Real: RealField,
{
    let b_norm = b.norm_l2();

    // Pre-allocate the basis matrix V_k. This is a key aspect of the one-pass
    // approach. While it reserves a potentially large contiguous block of memory,
    // it avoids incremental resizing, which would be highly inefficient.
    let mut v_k = Mat::<T>::zeros(operator.nrows(), k);

    // Pre-allocate vectors for the scalar coefficients with a capacity hint to
    // prevent reallocations during the main loop.
    let mut alphas = Vec::with_capacity(k);
    let mut betas = Vec::with_capacity(k - 1);

    // Initialize the stateful Lanczos iterator.
    let mut lanczos_iter = LanczosIteration::new(operator, b, k, T::Real::copy_impl(&b_norm))?;

    // The first Lanczos vector is the normalized input vector `b`.
    v_k.col_mut(0)
        .copy_from(lanczos_iter.v_curr.as_ref().col(0));

    let mut steps_taken = 0;

    for i in 0..k {
        if let Some(step) = lanczos_iter.next_step(stack) {
            alphas.push(step.alpha);
            steps_taken += 1;

            // If a callback is provided, invoke it with the current state. This allows
            // for external logic to monitor the process without modifying the core algorithm.
            if let Some(ref mut cb) = callback {
                // We provide a view into the valid portion of the basis matrix.
                let current_v_k = v_k.as_ref().get(.., 0..steps_taken);
                let t_k_view = TridiagonalSystemView {
                    alphas: &alphas,
                    betas: &betas,
                    steps_taken,
                };

                // The callback can signal for an early, graceful stop.
                if !cb(steps_taken, current_v_k, &t_k_view) {
                    break;
                }
            }

            // A zero (or numerically zero) beta indicates that breakdown has occurred.
            // The Krylov subspace is invariant, and the iteration must terminate.
            let tolerance = breakdown_tolerance::<T::Real>();
            if step.beta <= tolerance {
                break;
            }

            // Store the off-diagonal element and the newly computed basis vector.
            // This is skipped in the final iteration as v_{k+1} is not needed.
            if i < k - 1 {
                betas.push(step.beta);
                // The `lanczos_iter` has already updated its internal state, so `v_curr`
                // now holds the next orthonormal vector, v_{i+1}.
                v_k.col_mut(i + 1)
                    .copy_from(lanczos_iter.v_curr.as_ref().col(0));
            }
        } else {
            // This branch is taken if the iterator terminates because k >= max_k.
            break;
        }
    }

    // --- Finalize the basis matrix V_k ---
    // This logic is critical for both correctness and memory efficiency.
    // If the algorithm terminated early (due to breakdown or callback), the pre-allocated
    // `v_k` matrix is larger than the number of valid basis vectors. We must return a
    // matrix of the correct dimensions.
    let final_v_k = if steps_taken == k {
        // The algorithm completed all k steps. We can move ownership of the correctly-sized
        // matrix `v_k` directly to the output structure. This is a zero-cost operation
        // that avoids a potentially very expensive clone of a large matrix.
        v_k
    } else {
        // Termination was early. We must allocate a new, smaller matrix and copy only the
        // valid columns. This slicing operation (`get`) creates a view, and `.to_owned()`
        // performs the allocation and copy.
        v_k.as_ref().get(.., 0..steps_taken).to_owned()
    };

    Ok(LanczosOutput {
        v_k: final_v_k,
        decomposition: LanczosDecomposition {
            alphas,
            betas,
            steps_taken,
            b_norm,
        },
    })
}

/// Performs the first pass of the two-pass Lanczos algorithm.
///
/// This pass computes the scalar decomposition of the operator's action on `b` by
/// executing the Lanczos iteration without storing the basis vectors. The sole output
/// is the [`LanczosDecomposition`] struct, which contains the essential scalar data
/// ($\alpha_j$, $\beta_j$, and $\|\mathbf{b}\|_2$) needed to reconstruct the basis and
/// solution in the second pass. This approach results in a minimal $O(n)$ memory footprint.
///
/// # Arguments
/// * `operator`: A linear operator that implements [`faer::matrix_free::LinOp`].
/// * `b`: The starting vector. Must not be a zero vector.
/// * `k`: The maximum number of iterations to perform.
/// * `stack`: A `MemStack` for temporary allocations.
///
/// # Returns
/// A `Result` containing the [`LanczosDecomposition`] on success, or a [`LanczosError`].
pub(crate) fn lanczos_pass_one<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    k: usize,
    stack: &mut MemStack,
) -> Result<LanczosDecomposition<T::Real>, LanczosError>
where
    T::Real: RealField,
{
    let b_norm = b.norm_l2();
    let mut alphas = Vec::with_capacity(k);
    let mut betas = Vec::with_capacity(k - 1);

    // The stateful Lanczos iterator handles the vector recurrence. In this pass,
    // we only care about the scalar results of each step.
    let mut lanczos_iter = LanczosIteration::new(operator, b, k, T::Real::copy_impl(&b_norm))?;

    let mut steps_taken = 0;

    for i in 0..k {
        if let Some(step) = lanczos_iter.next_step(stack) {
            alphas.push(step.alpha);
            steps_taken += 1;

            // Check for breakdown, which terminates the process.
            let tolerance = breakdown_tolerance::<T::Real>();
            if step.beta <= tolerance {
                break;
            }

            // Store the off-diagonal element, but discard the basis vector.
            if i < k - 1 {
                betas.push(step.beta);
            }
        } else {
            break;
        }
    }

    Ok(LanczosDecomposition {
        alphas,
        betas,
        steps_taken,
        b_norm,
    })
}

/// Performs the second pass of the two-pass Lanczos algorithm.
///
/// This pass reconstructs the solution vector $\mathbf{x}_k = \mathbf{V}_k \mathbf{y}_k$
/// by regenerating the Lanczos basis vectors on-the-fly using the coefficients from the
/// first pass. It avoids storing the full basis, thus maintaining an $O(n)$ memory footprint.
///
/// This is a thin wrapper around the core implementation, `lanczos_pass_two_impl`,
/// configured to not store the regenerated basis, ensuring minimal memory usage for the public API.
///
/// # Arguments
/// * `operator`: The linear operator $\mathbf{A}$.
/// * `b`: The original starting vector.
/// * `decomposition`: The scalar data generated by `lanczos_pass_one`.
/// * `y_k`: The coefficient vector for the solution in the Lanczos basis, i.e.,
///   $\mathbf{y}_k = f(\mathbf{T}_k) \mathbf{e}_1 \|\mathbf{b}\|_2$.
/// * `stack`: A `MemStack` for temporary allocations.
///
/// # Returns
/// A `Result` containing the final approximate solution vector $\mathbf{x}_k$.
pub(crate) fn lanczos_pass_two<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    decomposition: &LanczosDecomposition<T::Real>,
    y_k: MatRef<'_, T>,
    stack: &mut MemStack,
) -> Result<Mat<T>, LanczosError>
where
    T::Real: RealField,
{
    let (x_k, _) = lanczos_pass_two_impl(operator, b, decomposition, y_k, stack, false)?;
    Ok(x_k)
}

/// A test-only variant of `lanczos_pass_two` that also returns the regenerated basis.
///
/// This function is identical to `lanczos_pass_two` but additionally returns the full
/// regenerated basis matrix $\mathbf{V}'_k$. It is used only during testing
/// and is used to verify the numerical stability and faithfulness of the regeneration process
/// by allowing a direct comparison with the basis stored by [`lanczos_standard`].
#[allow(dead_code)]
pub fn lanczos_pass_two_with_basis<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    decomposition: &LanczosDecomposition<T::Real>,
    y_k: MatRef<'_, T>,
    stack: &mut MemStack,
) -> Result<LanczosPassTwoOutput<T>, LanczosError>
where
    T::Real: RealField,
{
    // Call the core implementation, configured to store the basis for testing purposes.
    let (x_k, v_k_option) = lanczos_pass_two_impl(operator, b, decomposition, y_k, stack, true)?;
    // The `v_k_option` is guaranteed to be `Some` because `store_basis` is true.
    Ok(LanczosPassTwoOutput {
        x_k,
        v_k: v_k_option.unwrap(),
    })
}

/// A specialized recurrence step for the basis reconstruction in the second pass.
///
/// This function applies the Lanczos three-term recurrence using pre-computed
/// coefficients $\alpha_j$ and $\beta_{j-1}$ to regenerate the next unnormalized basis vector.
/// It avoids re-computing any coefficients, making it a pure reconstruction tool that is
/// both more efficient and numerically faithful to the sequence of operations in the first pass.
///
/// The recurrence applied is: $\mathbf{w} = \mathbf{A}\mathbf{v}_j - \alpha_j \mathbf{v}_j - \beta_{j-1}\mathbf{v}_{j-1}$.
fn lanczos_reconstruction_step<T: ComplexField, O: LinOp<T>>(
    operator: &O,
    mut w: MatMut<'_, T>,
    v_curr: MatRef<'_, T>,
    v_prev: MatRef<'_, T>,
    alpha_j: T::Real,
    beta_prev: T::Real,
    stack: &mut MemStack,
) {
    // 1. Apply the operator.
    operator.apply(w.rb_mut(), v_curr, Par::Seq, stack);

    // 2. Orthogonalize against the previous vector using the stored \beta_{j-1}.
    let beta_prev_scaled = T::from_real_impl(&beta_prev);
    zip!(w.rb_mut(), v_prev).for_each(|unzip!(w_i, v_prev_i)| {
        *w_i = sub(w_i, &mul(&beta_prev_scaled, v_prev_i));
    });

    // 3. Orthogonalize against the current vector using the stored \alpha_j.
    let alpha_scaled = T::from_real_impl(&alpha_j);
    zip!(w.rb_mut(), v_curr).for_each(|unzip!(w_i, v_curr_i)| {
        *w_i = sub(w_i, &mul(&alpha_scaled, v_curr_i));
    });
}

/// Core implementation of the second Lanczos pass.
///
/// This private function contains the logic to regenerate the basis and reconstruct the solution.
/// It can be configured via the `store_basis` flag to either store the full regenerated basis
/// (for testing and verification) or discard it (for production use, ensuring $O(n)$ memory).
fn lanczos_pass_two_impl<T: ComplexField>(
    operator: &impl LinOp<T>,
    b: MatRef<'_, T>,
    decomposition: &LanczosDecomposition<T::Real>,
    y_k: MatRef<'_, T>,
    stack: &mut MemStack,
    store_basis: bool,
) -> Result<(Mat<T>, Option<Mat<T>>), LanczosError>
where
    T::Real: RealField,
{
    // --- Input Validation ---
    // Ensure the coefficient vector `y_k` has the correct dimension, matching the
    // number of steps successfully completed in the first pass.
    if decomposition.steps_taken != y_k.nrows() {
        return Err(LanczosErrorKind::ParameterMismatch {
            param_name: "y_k".to_string(),
            expected: decomposition.steps_taken,
            actual: y_k.nrows(),
        }
        .into());
    }

    let zero_threshold = breakdown_tolerance::<T::Real>();
    if decomposition.b_norm <= zero_threshold {
        return Err(LanczosErrorKind::InputError(
            "The initial vector `b` must not be a zero vector.".to_string(),
        )
        .into());
    }

    if decomposition.steps_taken == 0 {
        let v_k = if store_basis {
            Some(Mat::zeros(b.nrows(), 0))
        } else {
            None
        };
        return Ok((Mat::zeros(b.nrows(), 1), v_k));
    }

    // --- Initialization ---
    let mut v_prev = Mat::<T>::zeros(b.nrows(), 1);
    let inv_norm = T::from_real_impl(&T::Real::recip_impl(&decomposition.b_norm));
    let mut v_curr = b * Scale(inv_norm); // This is v_1

    // Initialize the solution vector with the first component: x_k = y_1 * v_1
    let mut x_k = &v_curr * Scale(T::copy_impl(&y_k[(0, 0)]));

    // If requested, initialize the matrix for storing the regenerated basis.
    let mut v_k_regen = if store_basis {
        let mut m = Mat::zeros(b.nrows(), decomposition.steps_taken);
        m.col_mut(0).copy_from(v_curr.as_ref().col(0));
        Some(m)
    } else {
        None
    };

    let mut work = Mat::<T>::zeros(b.nrows(), 1);

    // --- Main Reconstruction Loop ---
    for j in 0..decomposition.steps_taken - 1 {
        // Retrieve the scalar coefficients computed during the first pass.
        let alpha_j = T::Real::copy_impl(&decomposition.alphas[j]);
        let beta_j = T::Real::copy_impl(&decomposition.betas[j]);
        let beta_prev = if j == 0 {
            T::Real::zero_impl()
        } else {
            T::Real::copy_impl(&decomposition.betas[j - 1])
        };

        // 1. Regenerate the unnormalized next vector, r_j, using the stored coefficients.
        lanczos_reconstruction_step(
            operator,
            work.as_mut(),
            v_curr.as_ref(),
            v_prev.as_ref(),
            alpha_j,
            beta_prev,
            stack,
        );

        // 2. Normalize the regenerated vector using the stored beta_j. The first pass
        // ensures that beta_j is not numerically zero at this step.
        let inv_beta = T::from_real_impl(&T::Real::recip_impl(&beta_j));
        zip!(work.as_mut()).for_each(|unzip!(w_i)| {
            *w_i = mul(w_i, &inv_beta);
        });
        // `work` now contains the regenerated vector v_{j+1}.

        // 3. Accumulate the final solution vector component-wise: x_k += y_{j+1} * v_{j+1}
        let coeff = T::copy_impl(&y_k[(j + 1, 0)]);
        zip!(x_k.as_mut(), work.as_ref()).for_each(|unzip!(x_i, v_i)| {
            *x_i = add(x_i, &mul(&coeff, v_i));
        });

        // 4. Cycle the vectors for the next iteration using efficient swaps.
        core::mem::swap(&mut v_prev, &mut v_curr);
        core::mem::swap(&mut v_curr, &mut work);

        // 5. If requested, store the regenerated basis vector.
        if let Some(m) = v_k_regen.as_mut() {
            m.col_mut(j + 1).copy_from(v_curr.as_ref().col(0));
        }
    }

    Ok((x_k, v_k_regen))
}

#[allow(dead_code)]
#[cfg(test)]
mod tests {
    use super::*;
    use crate::utils::data_loader::load_kkt_system;
    use anyhow::{Result, ensure};
    use faer::dyn_stack::MemBuffer;
    use rand::{Rng, SeedableRng, rngs::StdRng};
    use std::path::PathBuf;

    // A tolerance for floating-point comparisons in property tests.
    const TOLERANCE: f64 = 5e-9;

    /// A helper struct to hold paths to a complete test instance.
    #[derive(Debug)]
    struct TestInstance {
        pub name: String,
        pub dmx_path: PathBuf,
        pub qfc_path: PathBuf,
    }

    /// Lightweight test problem for basic unit tests.
    fn setup_simple_problem() -> (Mat<f64>, Mat<f64>) {
        let a: Mat<f64> = mat![
            [2.0, -1.0, 0.0, 0.0],
            [-1.0, 2.0, -1.0, 0.0],
            [0.0, -1.0, 2.0, -1.0],
            [0.0, 0.0, -1.0, 2.0],
        ];
        let b: Mat<f64> = mat![[1.0], [2.0], [3.0], [4.0]];
        (a, b)
    }

    // --- UNIT TESTS ---

    #[test]
    fn test_recurrence_step_correctness() {
        let (a, _) = setup_simple_problem();
        let mut mem = MemBuffer::new(a.apply_scratch(1, Par::Seq));
        let stack = MemStack::new(&mut mem);

        let v_curr: Mat<f64> = mat![[1.0], [0.0], [0.0], [0.0]];
        let v_prev: Mat<f64> = Mat::zeros(4, 1);
        let beta_prev = 0.0;

        let mut work = Mat::<f64>::zeros(4, 1);
        let (alpha, beta_option) = lanczos_recurrence_step(
            &a.as_ref(),
            work.as_mut(),
            v_curr.as_ref(),
            v_prev.as_ref(),
            beta_prev,
            stack,
        );

        let beta = beta_option.unwrap();
        assert!((alpha - 2.0).abs() < 1e-15);
        assert!((beta - 1.0).abs() < 1e-15);
    }

    #[test]
    fn test_breakdown_scenario() {
        let a: Mat<f64> = mat![[2.0, 0.0], [0.0, 3.0]];
        let b: Mat<f64> = mat![[1.0], [0.0]];
        let k = 2;
        let mut mem = MemBuffer::new(a.apply_scratch(1, Par::Seq));
        let stack = MemStack::new(&mut mem);

        let result = lanczos_standard(&a.as_ref(), b.as_ref(), k, stack, None).unwrap();
        assert_eq!(result.decomposition.steps_taken, 1);
    }

    #[test]
    fn test_zero_vector_input_returns_error() {
        let a: Mat<f64> = Mat::identity(2, 2);
        let b: Mat<f64> = Mat::zeros(2, 1);
        let mut mem = MemBuffer::new(a.apply_scratch(1, Par::Seq));
        let stack = MemStack::new(&mut mem);
        assert!(lanczos_standard(&a, b.as_ref(), 2, stack, None).is_err());
    }

    // --- PROPERTY TESTS (RUNNERS) ---

    /// Verifies that the scalar decompositions from the one-pass and two-pass
    /// algorithms are consistent to within floating-point tolerance.
    fn run_decomposition_consistency_test_for_instance(instance: &TestInstance) -> Result<()> {
        let k = 30;
        let kkt_system = load_kkt_system(&instance.dmx_path, &instance.qfc_path)?;
        let a = kkt_system.a;
        let n = a.nrows();
        let mut rng = StdRng::seed_from_u64(42);
        let b = Mat::from_fn(n, 1, |_, _| rng.random());
        let mut mem = MemBuffer::new(a.as_ref().apply_scratch(1, Par::Seq));
        let stack = MemStack::new(&mut mem);

        let standard_output = lanczos_standard(&a.as_ref(), b.as_ref(), k, stack, None)?;
        let pass_one_output = lanczos_pass_one(&a.as_ref(), b.as_ref(), k, stack)?;

        ensure!(
            standard_output.decomposition.steps_taken == pass_one_output.steps_taken,
            "steps_taken mismatch on instance '{}'",
            instance.name
        );

        for (i, (alpha_std, alpha_po)) in standard_output
            .decomposition
            .alphas
            .iter()
            .zip(pass_one_output.alphas.iter())
            .enumerate()
        {
            ensure!(
                (alpha_std - alpha_po).abs() < TOLERANCE,
                "Alpha mismatch at index {} on instance '{}'",
                i,
                instance.name,
            );
        }
        for (i, (beta_std, beta_po)) in standard_output
            .decomposition
            .betas
            .iter()
            .zip(pass_one_output.betas.iter())
            .enumerate()
        {
            ensure!(
                (beta_std - beta_po).abs() < TOLERANCE,
                "Beta mismatch at index {} on instance '{}'",
                i,
                instance.name,
            );
        }
        Ok(())
    }

    /// Verifies that the fundamental Lanczos relation A*V_k - V_k*T_k = beta_k*v_{k+1}*e_k^T
    /// holds for the standard algorithm.
    fn run_lanczos_relation_test_for_instance(instance: &TestInstance) -> Result<()> {
        let k = 30;
        let kkt_system = load_kkt_system(&instance.dmx_path, &instance.qfc_path)?;
        let a = kkt_system.a;
        let n = a.nrows();
        let mut rng = StdRng::seed_from_u64(42);
        let b = Mat::from_fn(n, 1, |_, _| rng.random());
        let mut mem = MemBuffer::new(a.as_ref().apply_scratch(1, Par::Seq));
        let stack = MemStack::new(&mut mem);

        let result_k = lanczos_standard(&a.as_ref(), b.as_ref(), k, stack, None)?;
        let result_k_plus_1 = lanczos_standard(&a.as_ref(), b.as_ref(), k + 1, stack, None)?;

        let v_k = result_k.v_k.as_ref();
        let beta_k = result_k_plus_1.decomposition.betas[k - 1];
        let v_k_plus_1 = result_k_plus_1.v_k.as_ref().get(.., k..k + 1);

        let t_k_mat = {
            let mut t = Mat::zeros(k, k);
            for i in 0..k {
                t.as_mut()[(i, i)] = result_k.decomposition.alphas[i];
            }
            for i in 0..k - 1 {
                t.as_mut()[(i, i + 1)] = result_k.decomposition.betas[i];
                t.as_mut()[(i + 1, i)] = result_k.decomposition.betas[i];
            }
            t
        };

        let mut e_k = Mat::zeros(k, 1);
        e_k.as_mut()[(k - 1, 0)] = 1.0;

        let residual_matrix = a.as_ref() * v_k - v_k * t_k_mat;
        let expected_residual_matrix = v_k_plus_1 * e_k.as_ref().adjoint() * Scale(beta_k);

        let norm_diff = (residual_matrix - expected_residual_matrix).norm_l2();
        ensure!(
            norm_diff < TOLERANCE,
            "Lanczos relation does not hold on instance '{}'. Diff norm: {}",
            instance.name,
            norm_diff
        );
        Ok(())
    }

    /// Verifies that the basis vectors generated by the standard algorithm are orthonormal.
    fn run_orthonormality_test_for_instance(instance: &TestInstance) -> Result<()> {
        let k = 30;
        let kkt_system = load_kkt_system(&instance.dmx_path, &instance.qfc_path)?;
        let a = kkt_system.a;
        let n = a.nrows();
        let mut rng = StdRng::seed_from_u64(42);
        let b = Mat::from_fn(n, 1, |_, _| rng.random());
        let mut mem = MemBuffer::new(a.as_ref().apply_scratch(1, Par::Seq));
        let stack = MemStack::new(&mut mem);

        let standard_output = lanczos_standard(&a.as_ref(), b.as_ref(), k, stack, None)?;
        let v_k_standard = standard_output.v_k.as_ref();
        let steps = standard_output.decomposition.steps_taken;
        let identity = Mat::<f64>::identity(steps, steps);
        let ortho_error_standard = (&identity - v_k_standard.adjoint() * v_k_standard).norm_l2();
        ensure!(
            ortho_error_standard < TOLERANCE,
            "Standard basis on instance '{}' is not orthonormal. Error norm: {}",
            instance.name,
            ortho_error_standard
        );
        Ok(())
    }

    /// Verifies the numerical stability of the two-pass method by measuring the
    /// drift between the standard and regenerated Lanczos bases.
    fn run_reconstruction_stability_test_for_instance(instance: &TestInstance) -> Result<()> {
        let k = 30;
        let kkt_system = load_kkt_system(&instance.dmx_path, &instance.qfc_path)?;
        let a = kkt_system.a;
        let n = a.nrows();
        let mut rng = StdRng::seed_from_u64(42);
        let b = Mat::from_fn(n, 1, |_, _| rng.random());
        let mut mem = MemBuffer::new(a.as_ref().apply_scratch(1, Par::Seq));
        let stack = MemStack::new(&mut mem);

        let standard_output = lanczos_standard(&a.as_ref(), b.as_ref(), k, stack, None)?;
        let v_k_ref = standard_output.v_k;
        let steps = standard_output.decomposition.steps_taken;

        let decomp = lanczos_pass_one(&a.as_ref(), b.as_ref(), k, stack)?;
        let y_k = Mat::from_fn(steps, 1, |i, _| 0.1 * (i + 1) as f64);

        let pass_two_output =
            lanczos_pass_two_with_basis(&a.as_ref(), b.as_ref(), &decomp, y_k.as_ref(), stack)?;
        let v_k_regenerated = pass_two_output.v_k;

        let drift = (v_k_ref - v_k_regenerated).squared_norm_l2();
        ensure!(
            drift < TOLERANCE,
            "Numerical drift between bases on instance '{}' is too high. Drift norm: {}",
            instance.name,
            drift
        );
        Ok(())
    }

    /// Macro to generate a test module that includes all dynamically generated
    /// test functions from the build script.
    macro_rules! generate_property_tests {
        () => {
            mod generated {
                use super::*;
                include!(concat!(env!("OUT_DIR"), "/lanczos_properties_tests.rs"));
            }
        };
    }

    generate_property_tests!();
}
